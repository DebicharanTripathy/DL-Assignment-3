# -*- coding: utf-8 -*-
"""DLAssignment3Question3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1DqDGGEZVZT6Ky_6_wyAHikCnXOoXE6My
"""

# Author: Debicharan Tripathy
#Roll no - M22ai545

#Implement GAN and use the Frey Face dataset to train your network. Generate new samples and comment on the quality of the faces.
#Dataset: https://cs.nyu.edu/âˆ¼roweis/data/frey rawface.mat

import torch
import torch.nn as nn
import torch.optim as optim
import numpy as np
from torch.utils.data import DataLoader, TensorDataset
import scipy.io
import matplotlib.pyplot as plt

# Load the Frey Face dataset
data = scipy.io.loadmat('frey_rawface.mat')
X = data['ff'].T.astype('float32')
num_samples, input_dim = X.shape

# Normalize the data to [0, 1]
X /= 255.0

# Convert to PyTorch Tensor
X_tensor = torch.from_numpy(X)

# Set random seed for reproducibility
torch.manual_seed(42)

# If a GPU is available, select it; otherwise, select a CPU.
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

# Hyperparameters
latent_dim = 100
hidden_dim = 256
learning_rate = 0.0002
batch_size = 64
num_epochs = 100

# Create DataLoader
dataset = TensorDataset(X_tensor)
dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)

# Generator network
class Generator(nn.Module):
    def __init__(self):
        super(Generator, self).__init__()
        self.model = nn.Sequential(
            nn.Linear(latent_dim, hidden_dim),
            nn.ReLU(),
            nn.Linear(hidden_dim, hidden_dim),
            nn.ReLU(),
            nn.Linear(hidden_dim, input_dim),
            nn.Sigmoid()
        )

    def forward(self, z):
        return self.model(z)

# Discriminator network
class Discriminator(nn.Module):
    def __init__(self):
        super(Discriminator, self).__init__()
        self.model = nn.Sequential(
            nn.Linear(input_dim, hidden_dim),
            nn.LeakyReLU(0.2),
            nn.Linear(hidden_dim, hidden_dim),
            nn.LeakyReLU(0.2),
            nn.Linear(hidden_dim, 1),
            nn.Sigmoid()
        )

    def forward(self, x):
        return self.model(x)

# Create the generator and discriminator from scratch.
generator = Generator().to(device)
discriminator = Discriminator().to(device)

# Optimizers and the loss function
adversarial_loss = nn.BCELoss()
generator_optimizer = optim.Adam(generator.parameters(), lr=learning_rate)
discriminator_optimizer = optim.Adam(discriminator.parameters(), lr=learning_rate)

# Training loop
for epoch in range(num_epochs):
    for i, real_images in enumerate(dataloader):
        real_images = real_images[0].to(device)
        batch_size = real_images.size(0)

        # Maximise log(D(x)) + log(1 - D(G(z))) to train the discriminator.
        discriminator.zero_grad()
        real_labels = torch.ones(batch_size, 1).to(device)
        fake_labels = torch.zeros(batch_size, 1).to(device)

        # Loss of discrimination for genuine images
        real_output = discriminator(real_images)
        d_loss_real = adversarial_loss(real_output, real_labels)

        # Create Fictitious/Fake images
        z = torch.randn(batch_size, latent_dim).to(device)
        fake_images = generator(z)

        # Discriminator loss for fake images
        fake_output = discriminator(fake_images.detach())  # Detach to avoid backpropagating to the generator
        d_loss_fake = adversarial_loss(fake_output, fake_labels)

        # Total discriminator loss
        d_loss = d_loss_real + d_loss_fake
        d_loss.backward()
        discriminator_optimizer.step()

        # Train the generator (minimize log(1 - D(G(z))))
        generator.zero_grad()
        valid_labels = torch.ones(batch_size, 1).to(device)

        # Generator loss
        output = discriminator(fake_images)
        g_loss = adversarial_loss(output, valid_labels)
        g_loss.backward()
        generator_optimizer.step()

    print(f"Epoch {epoch + 1}/{num_epochs}, Discriminator Loss: {d_loss.item()}, Generator Loss: {g_loss.item()}")

# Create fresh samples via the skilled/trained generator.
generator.eval()
num_generated_samples = 25
with torch.no_grad():
    z = torch.randn(num_generated_samples, latent_dim).to(device)
    generated_samples = generator(z).cpu().numpy()

# Display the generated samples
fig, axs = plt.subplots(5, 5, figsize=(8, 8))
for i in range(5):
    for j in range(5):
        idx = i * 5 + j
        sample = generated_samples[idx].reshape(28, 20)
        axs[i, j].imshow(sample, cmap='gray')
        axs[i, j].axis('off')
plt.show()